# Contract: Chapter Structure Definition

**Version**: 1.0.0
**Type**: Content Template

## Overview
This contract defines the mandatory structure for "Chapter 4: Vision-Language-Action". Any implementation must adhere to these sections.

## Schema

### 1. Header
*   **Title**: Must be "Vision-Language-Action: The Convergence".
*   **Abstract**: A 100-word summary of how LLMs enable high-level robot autonomy.

### 2. Learning Objectives
*   Must list at least 3 distinct objectives:
    1.  Define the VLA loop (Vision-Language-Action).
    2.  Explain the concept of "Grounding" in robotics.
    3.  Critique the safety implications of LLM-controlled robots.

### 3. Core Sections
*   **4.1 Introduction**: From "Chatbots" to "Robot Brains".
*   **4.2 Voice-to-Action**: The "Ear" (Whisper) and "Mouth" (TTS).
*   **4.3 Cognitive Planning**: The "Prefrontal Cortex" (LLM + Prompt Engineering).
*   **4.4 The Scene Graph**: Bridging Vision and Language (JSON representations).
*   **4.5 Capstone Project**: "The Autonomous Tidying Robot" (Walkthrough).

### 4. Pedagogical Elements
*   **Callouts**: Must include a "Hallucination Warning" (e.g., Robot inventing a 'Flying' skill).
*   **Diagrams**:
    *   Full VLA Architecture (Audio -> Text -> Plan -> Action).
    *   Scene Graph Visualization.
    *   Prompt Engineering Example (System Prompt vs User Prompt).

### 5. Summary & Review
*   **Key Takeaways**: Bulleted list.
*   **Future Outlook**: Where is VLA going? (End-to-end vs. Modular).
*   **Quiz**: Conceptual questions on Grounding and Safety.
